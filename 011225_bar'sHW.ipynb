{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717a6836-b85d-46a3-861d-371c4d8db732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27c32ac-5e70-4c70-82a0-5e9e094c559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = np.array([2, 4, 6, 8, 10, 12, 14]).reshape(-1, 1)\n",
    "y = np.array([1, 2, 5, 8, 12, 14, 15])\n",
    "Xst8 = np.array([2, 4, 6, 8, 10, 12, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d72eb3-e12d-40bc-b227-478e5de7cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1---\n",
      " 27.836734693877556\n",
      "---3&4---\n",
      "true mse: 7.5 , true mean: 4.0\n",
      "false mse: 1.5555555555555556 , false mean: 13.666666666666666\n",
      "---5---\n",
      "weighted mse: 4.9523809523809526\n",
      "---6---\n",
      "mse gain: 22.884353741496604\n"
     ]
    }
   ],
   "source": [
    "def MSE(x): \n",
    "    n=len(x)\n",
    "    p=(x-np.mean(x))**2\n",
    "    return (sum(p)/n)\n",
    "\n",
    "mse=MSE(y)\n",
    "print('---1---\\n',mse)\n",
    "\n",
    "cond=lambda v: v <= 9 #---->2\n",
    "ytrue=y[cond(Xst8)]\n",
    "yfalse=y[~(cond(Xst8))]\n",
    "\n",
    "msetrue=MSE(ytrue)\n",
    "msefalse=MSE(yfalse)\n",
    "print(f'---3&4---\\ntrue mse: {msetrue} , true mean: {np.mean(ytrue)}\\nfalse mse: {msefalse} , false mean: {np.mean(yfalse)}')\n",
    "weighted_mse = (len(ytrue)/len(y))*msetrue + (len(yfalse)/len(y))*msefalse\n",
    "print(f'---5---\\nweighted mse: {weighted_mse}')\n",
    "gain = MSE(y) - weighted_mse\n",
    "print(f'---6---\\nmse gain:',gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289fbbc7-342c-4df9-983c-20860924bf8b",
   "metadata": {},
   "source": [
    "Let scikit-learn Build the Tree\n",
    "\n",
    "Now we let scikit-learn build a regression tree of depth 1 and compare to our manual work\n",
    "\n",
    "1.Complete the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cabb0e3-bedf-40bb-9b98-12e1a022598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_test --> 16.916666666666668 \n",
      " r2_test  --> 0.5151273885350318\n",
      "|--- x <= 9.00\n",
      "|   |--- value: [6.50]\n",
      "|--- x >  9.00\n",
      "|   |--- value: [13.50]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array([2, 4, 6, 8, 10, 12, 14]).reshape(-1, 1)\n",
    "y = np.array([1, 2, 5, 8, 12, 14, 15])\n",
    "\n",
    "# Regression tree with depth 1\n",
    "tree = DecisionTreeRegressor(\n",
    "    criterion=\"squared_error\",  # MSE criterion\n",
    "    max_depth=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the tree\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "tree.fit(X_train, y_train) \n",
    "\n",
    "# calc MSE and R square\n",
    "y_pred_test=tree.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print('mse_test -->',mse_test,'\\n','r2_test  -->',r2_test)\n",
    "# Show the tree structure\n",
    "rules = export_text(tree, feature_names=[\"x\"])\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d635975e-7da9-44a2-aef3-8643fc1132ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- depth = 2 ---\n",
      "Train MSE: 0.0  | Train R²: 1.0\n",
      "Test  MSE: 9.666666666666666  | Test  R²: 0.7229299363057324\n",
      "|--- x <= 9.00\n",
      "|   |--- x <= 7.00\n",
      "|   |   |--- value: [5.00]\n",
      "|   |--- x >  7.00\n",
      "|   |   |--- value: [8.00]\n",
      "|--- x >  9.00\n",
      "|   |--- x <= 12.00\n",
      "|   |   |--- value: [12.00]\n",
      "|   |--- x >  12.00\n",
      "|   |   |--- value: [15.00]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def best_r2(X,y,depth):\n",
    "    tree = DecisionTreeRegressor(\n",
    "    criterion=\"squared_error\",  # MSE criterion\n",
    "    max_depth=depth,\n",
    "    random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    tree.fit(X_train, y_train) \n",
    "    y_pred_test=tree.predict(X_test)\n",
    "    y_pred_train=tree.predict(X_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test  = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test  = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"--- depth = {depth} ---\")\n",
    "    print(\"Train MSE:\", mse_train, \" | Train R²:\", r2_train)\n",
    "    print(\"Test  MSE:\", mse_test,  \" | Test  R²:\", r2_test)\n",
    "    # Show the tree structure\n",
    "    rules = export_text(tree, feature_names=[\"x\"])\n",
    "    print(rules)\n",
    "best_r2(X,y,2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae05812-aac2-43c9-b875-f2f2af9fd3e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (545767734.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mגיליתי שמעל עומק של 2, המודל מפסיק להצמיח עוד ענפים כי הוא מגיע ל-MSE הכי טוב ואין פיצול נוסף שיכול לגרום לשיפור כלשהו.\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "גיליתי שמעל עומק של 2, המודל מפסיק להצמיח עוד ענפים כי הוא מגיע ל-MSE הכי טוב ואין פיצול נוסף שיכול לגרום לשיפור כלשהו.\n",
    "לגבי ה-overfitting, בגלל שמדובר במערך קטן הסיכוי ל-overfitting תמיד גדל.\n",
    "מה-train אפשר לראות שהתוצאות הן מושלמות אז יש overfitting, אבל מכיוון שתוצאות של ה-test \"לא נופלות רחוק מדי\" מה-train, המודל עדיין מספיק טוב כדי לתת פרדיקציות טובות."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
